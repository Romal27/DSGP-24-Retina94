{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Imports",
   "id": "17c013ba2295c749"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T19:37:23.339464Z",
     "start_time": "2025-01-24T19:37:23.336709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd"
   ],
   "id": "ab3867fd5132914",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Defining paths and loading the 3 csv files",
   "id": "33a83a535ec75e2a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T19:37:23.363757Z",
     "start_time": "2025-01-24T19:37:23.357715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_image_folder_path = '/Users/teransenevirathne/Desktop/Dataset/train_images/train_images'\n",
    "test_image_folder_path = '/Users/teransenevirathne/Desktop/Dataset/test_images/test_images'\n",
    "val_image_folder_path = '/Users/teransenevirathne/Desktop/Dataset/val_images/val_images'\n",
    "\n",
    "train_csv_path = '/Users/teransenevirathne/Desktop/Dataset/train.csv'\n",
    "test_csv_path = '/Users/teransenevirathne/Desktop/Dataset/test.csv'\n",
    "val_csv_path = '/Users/teransenevirathne/Desktop/Dataset/valid.csv'\n",
    "\n",
    "train_data = pd.read_csv(train_csv_path)\n",
    "val_data = pd.read_csv(val_csv_path)\n",
    "test_data = pd.read_csv(test_csv_path)"
   ],
   "id": "2539bdce3810bde2",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Checking for missing images in train set",
   "id": "7c0a90dd0e77a830"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T19:37:23.421987Z",
     "start_time": "2025-01-24T19:37:23.369162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_missing_images = []\n",
    "for image_id in train_data['id_code']:\n",
    "    image_filename = image_id + \".png\"\n",
    "    image_path = os.path.join(train_image_folder_path, image_filename)\n",
    "    if not os.path.exists(image_path):\n",
    "        train_missing_images.append(image_id)\n",
    "print(\"Total Images in Train Folder:\", len(os.listdir(train_image_folder_path)))\n",
    "print(\"Total Images in Train CSV:\", len(train_data))\n",
    "print(\"Missing Images in Train Dataset:\", len(train_missing_images))\n",
    "if len(train_missing_images) > 0:\n",
    "    print(\"Missing Images:\", train_missing_images)"
   ],
   "id": "e49f0efe6d1bff9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Images in Train Folder: 2930\n",
      "Total Images in Train CSV: 2930\n",
      "Missing Images in Train Dataset: 0\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Checking for missing images in test set",
   "id": "d8a944b36460cb79"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T19:37:23.456972Z",
     "start_time": "2025-01-24T19:37:23.446648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_missing_images = []\n",
    "for image_id in test_data['id_code']:\n",
    "    image_filename = image_id + \".png\"\n",
    "    image_path = os.path.join(test_image_folder_path, image_filename)\n",
    "    if not os.path.exists(image_path):\n",
    "        test_missing_images.append(image_id)\n",
    "print(\"Total Images in Test Folder:\", len(os.listdir(test_image_folder_path)))\n",
    "print(\"Total Images in Test CSV:\", len(test_data))\n",
    "print(\"Missing Images in Test Dataset:\", len(test_missing_images))\n",
    "if len(test_missing_images) > 0:\n",
    "    print(\"Missing Images:\", test_missing_images)"
   ],
   "id": "acff397e15882650",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Images in Test Folder: 366\n",
      "Total Images in Test CSV: 366\n",
      "Missing Images in Test Dataset: 0\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Checking for missing images in validation set",
   "id": "5d077a4e037c041a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T19:37:23.482533Z",
     "start_time": "2025-01-24T19:37:23.475107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "validation_missing_images = []\n",
    "for image_id in val_data['id_code']:\n",
    "    image_filename = image_id + \".png\"\n",
    "    image_path = os.path.join(val_image_folder_path, image_filename)\n",
    "    if not os.path.exists(image_path):\n",
    "        validation_missing_images.append(image_id)\n",
    "print(\"Total Images in Validation Folder:\", len(os.listdir(val_image_folder_path)))\n",
    "print(\"Total Images in Validation CSV:\", len(val_data))\n",
    "print(\"Missing Images in Validation Dataset:\", len(validation_missing_images))\n",
    "if len(validation_missing_images) > 0:\n",
    "    print(\"Missing Images:\", validation_missing_images)"
   ],
   "id": "2a9e83bd78e39b5e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Images in Validation Folder: 366\n",
      "Total Images in Validation CSV: 366\n",
      "Missing Images in Validation Dataset: 0\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Imports",
   "id": "23502dfa80646dbf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T17:14:20.219088Z",
     "start_time": "2025-01-24T17:14:20.038031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd"
   ],
   "id": "e61b7bf7bb208c62",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Defining paths and loading the 3 csv files",
   "id": "295e2f5527018805"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T17:14:20.227510Z",
     "start_time": "2025-01-24T17:14:20.221960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_image_folder_path = '/Users/teransenevirathne/Desktop/Dataset/train_images/train_images'\n",
    "test_image_folder_path = '/Users/teransenevirathne/Desktop/Dataset/test_images/test_images'\n",
    "val_image_folder_path = '/Users/teransenevirathne/Desktop/Dataset/val_images/val_images'\n",
    "\n",
    "train_csv_path = '/Users/teransenevirathne/Desktop/Dataset/train.csv'\n",
    "test_csv_path = '/Users/teransenevirathne/Desktop/Dataset/test.csv'\n",
    "val_csv_path = '/Users/teransenevirathne/Desktop/Dataset/valid.csv'\n",
    "\n",
    "train_data = pd.read_csv(train_csv_path)\n",
    "val_data = pd.read_csv(val_csv_path)\n",
    "test_data = pd.read_csv(test_csv_path)"
   ],
   "id": "21fc245ac95ac62d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Checking for missing images in train set",
   "id": "25d7921a0443fd5a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T17:14:20.306410Z",
     "start_time": "2025-01-24T17:14:20.295197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_missing_images = []\n",
    "for image_id in train_data['id_code']:\n",
    "    image_filename = image_id + \".png\"\n",
    "    image_path = os.path.join(train_image_folder_path, image_filename)\n",
    "    if not os.path.exists(image_path):\n",
    "        train_missing_images.append(image_id)\n",
    "print(\"Total Images in Train Folder:\", len(os.listdir(train_image_folder_path)))\n",
    "print(\"Total Images in Train CSV:\", len(train_data))\n",
    "print(\"Missing Images in Train Dataset:\", len(train_missing_images))\n",
    "if len(train_missing_images) > 0:\n",
    "    print(\"Missing Images:\", train_missing_images)"
   ],
   "id": "425f77817efdd7e7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Images in Train Folder: 2930\n",
      "Total Images in Train CSV: 2930\n",
      "Missing Images in Train Dataset: 0\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Checking for missing images in test set",
   "id": "c7cce98000450fe7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T17:14:20.315737Z",
     "start_time": "2025-01-24T17:14:20.312383Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_missing_images = []\n",
    "for image_id in test_data['id_code']:\n",
    "    image_filename = image_id + \".png\"\n",
    "    image_path = os.path.join(test_image_folder_path, image_filename)\n",
    "    if not os.path.exists(image_path):\n",
    "        test_missing_images.append(image_id)\n",
    "print(\"Total Images in Test Folder:\", len(os.listdir(test_image_folder_path)))\n",
    "print(\"Total Images in Test CSV:\", len(test_data))\n",
    "print(\"Missing Images in Test Dataset:\", len(test_missing_images))\n",
    "if len(test_missing_images) > 0:\n",
    "    print(\"Missing Images:\", test_missing_images)"
   ],
   "id": "77fa02ae5c32602",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Images in Test Folder: 366\n",
      "Total Images in Test CSV: 366\n",
      "Missing Images in Test Dataset: 0\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Checking for missing images in validation set",
   "id": "b7342f29370d9ef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T17:14:20.326354Z",
     "start_time": "2025-01-24T17:14:20.322131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "validation_missing_images = []\n",
    "for image_id in val_data['id_code']:\n",
    "    image_filename = image_id + \".png\"\n",
    "    image_path = os.path.join(val_image_folder_path, image_filename)\n",
    "    if not os.path.exists(image_path):\n",
    "        validation_missing_images.append(image_id)\n",
    "print(\"Total Images in Validation Folder:\", len(os.listdir(val_image_folder_path)))\n",
    "print(\"Total Images in Validation CSV:\", len(val_data))\n",
    "print(\"Missing Images in Validation Dataset:\", len(validation_missing_images))\n",
    "if len(validation_missing_images) > 0:\n",
    "    print(\"Missing Images:\", validation_missing_images)"
   ],
   "id": "4a696e7df4b81d7d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Images in Validation Folder: 366\n",
      "Total Images in Validation CSV: 366\n",
      "Missing Images in Validation Dataset: 0\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (tensorflow)",
   "language": "python",
   "name": "python312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
